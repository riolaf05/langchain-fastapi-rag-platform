{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-31 15:16:30.729 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\ELAFACRB1\\venvs\\langchain\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from PyPDF2 import PdfFileReader\n",
    "import streamlit_authenticator as stauth\n",
    "# import json\n",
    "from PIL import Image\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "# sys.path.append('..\\embedding')\n",
    "from utils import AWSTexttract, LangChainAI, AWSS3, AWSTranscribe, DynamoDBManager, ChromaDBManager, TextSplitter, EmbeddingFunction\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "# from trubrics.integrations.streamlit import FeedbackCollector\n",
    "import logging\n",
    "load_dotenv('.env', override=True)\n",
    "from mutagen.mp3 import MP3\n",
    "from st_files_connection import FilesConnection\n",
    "import datetime\n",
    "from decimal import Decimal\n",
    "from streamlit_cognito_auth import CognitoAuthenticator #https://github.com/pop-srw/streamlit-cognito-auth\n",
    "# import subprocess\n",
    "\n",
    "lang=\"ITA\"\n",
    "JOB_URI=\"s3://riassume-transcribe-bucket/\"\n",
    "S3_BUCKET='riassume-transcribe-bucket'\n",
    "COGNITO_USER_POOL='us-east-1_2gJgqtGK3'\n",
    "COGNITO_CLIENT_ID='1hbdf29bl3goifqovdsga02kov'\n",
    "COLLECTION_NAME=\"media-chat-service\"\n",
    "table_name = \"chatgpt-summary-users\"\n",
    "langchain_client = LangChainAI()\n",
    "s3_client=AWSS3('riassume-document-bucket')\n",
    "conn = st.experimental_connection('s3', type=FilesConnection)\n",
    "transcribe_s3client = AWSS3(S3_BUCKET)\n",
    "transcribe = AWSTranscribe(JOB_URI)\n",
    "textract = AWSTexttract()\n",
    "dynamo_manager = DynamoDBManager(os.getenv('AWS_REGION'), table_name)\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# UPLOAD_FOLDER = '/tmp' #on Linux/Docker\n",
    "UPLOAD_FOLDER = r\"C:\\Users\\ELAFACRB1\\Codice\\GitHub\\chatgpt-summmary\\uploads\" #on Winzozz\n",
    "SQS_URL = os.getenv('SQS_URL')\n",
    "dbClient = ChromaDBManager() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
     ]
    }
   ],
   "source": [
    "# embedderFactory = EmbeddingFunction('bgeEmbedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedder = embedderFactory.embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceBgeEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': True}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
       "  (2): Normalize()\n",
       "), model_name='BAAI/bge-small-en-v1.5', cache_folder=None, model_kwargs={'device': 'cuda'}, encode_kwargs={'normalize_embeddings': True}, query_instruction='Represent this question for searching relevant passages: ')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<class 'openai.api_resources.embedding.Embedding'>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base='', openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization='', allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=6, request_timeout=None, headers=None, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedderFactory = EmbeddingFunction('openAI')\n",
    "embedder = embedderFactory.embedder\n",
    "embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "\n",
    "## Text Splitting & Docloader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_doc_retriever(collection):\n",
    "\n",
    "    # This text splitter is used to create the child documents\n",
    "    child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)\n",
    "\n",
    "\n",
    "    # The vectorstore to use to index the child chunks\n",
    "    vectorstore = Chroma(\n",
    "        collection_name=collection,\n",
    "        embedding_function=embedder  #OpenAIEmbeddings()\n",
    "    )\n",
    "\n",
    "    # The storage layer for the parent documents\n",
    "    store = InMemoryStore()\n",
    "\n",
    "    full_doc_retriever = ParentDocumentRetriever(\n",
    "        vectorstore=vectorstore,\n",
    "        docstore=store,\n",
    "        child_splitter=child_splitter,\n",
    "    )\n",
    "\n",
    "    return full_doc_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chunk_persist_pdf(path) -> Chroma:\n",
    "    #read pdf from folder\n",
    "    pdf_folder_path = path\n",
    "    documents = []\n",
    "    for file in os.listdir(pdf_folder_path):\n",
    "        if file.endswith('.pdf'):\n",
    "            pdf_path = os.path.join(pdf_folder_path, file)\n",
    "            loader = PyPDFLoader(pdf_path)\n",
    "            documents.extend(loader.load())\n",
    "\n",
    "    #split text and create documents\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "    chunked_documents = text_splitter.split_documents(documents)\n",
    "    return chunked_documents\n",
    "    # if client.list_collections():\n",
    "    #     consent_collection = client.create_collection(\"consent_collection\")\n",
    "    # else:\n",
    "    #     print(\"Collection already exists\")\n",
    "    # vectordb = Chroma.from_documents(\n",
    "    #     documents=chunked_documents,\n",
    "    #     embedding=OpenAIEmbeddings(),\n",
    "    #     persist_directory=os.getenv(\"PERSIST_DIR_PATH\")\n",
    "    # )\n",
    "    # vectordb.persist()\n",
    "    # return vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m PyPaperBot --query=\"Document Parent Retrieval\" --scholar-pages=4-7 --dwn-dir=os.getenv(\"PDF_FOLDER_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_chunk_persist_pdf(os.getenv(\"PDF_FOLDER_PATH\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='A Brief Review of Machine Learning and its \\nApplication \\nWANG Hua \\nInformation Engineering Institute \\nCapital Normal University \\nBeijing, 100048, China \\nwanghua1820@163.com MA Cuiqin \\nInformation Engineering Institute \\nCapital Normal University \\nBeijing, 100048, China \\nlife8431@163.com \\nZHOU Lijuan \\nInformation Engineering Institute \\nCapital Normal University \\nBeijing, 100048, China \\nzlj87@tom.com \\nAbstract —With the popularization of information and the \\nestablishment of the databases in great number, and how to \\nextract data from the useful information is the urgent problem to \\nbe solved. Machine learning is the core issue of artificial \\nintelligence research, this paper introduces the definition of \\nmachine learning and its basic structure, and describes a variety \\nof machine learning methods, including rote learning, inductive \\nlearning, analogy learning , explained learning, learning based on \\nneural network and knowledge discovery and so on. This paper \\nalso brings foreword the objectives of machine learning, and \\npoints out the development trend of machine learning. \\nKeywords-machine learning; intelligence; methods; application \\nI. I NTRODUCTION \\nLearning is the main hallmark of human intelligence and \\nthe basic means to obtain knowledge. Machine learning is the \\nfundamental way to make the computer intelligent. R.Shank has said: \"If a computer can not learn, it will not be called \\nintelligent.\" Since learning is an integrative mental activity \\nwith memory, thinking, perception, feeling, and other mental activities closely related. So, researchers from different fields give a different interpretation with different disciplines \\nrespectively, and give some different points of view. \\nII. M\\nACHINE LEARNING\\nMachine learning is a subject that studies how to use \\ncomputers to simulate human learning activities, and to study \\nself-improvement methods of computers that to obtain new \\nknowledge and new skills, identify existing knowledge, and \\ncontinuously improve the performance and achievement. \\nCompared with human learning, machine learning learns \\nfaster, the accumulation of knowledge is more facilitate the \\nresults of learning spread easier. So, any progress of human in \\nthe field of machine learning, will enhance the capability of computers, thus have an impact on human society. III. T\\nHE BASIC MODEL OF MACHINE LEARNING\\nTake the definition of learning from H•Simon [1] as the \\nstarting point, and establish the basic model shown in Fig. 1. In \\nthe process of machine learning, the quality of information that external environment provides to the system is the primary \\nfactor. The external environment is outside information set that delivers itself in some form, it represents sources of outside information; Learning is the process that processes the outside \\ninformation to knowledge, first it obtains the information of outside environment and then processes the information to \\nknowledge, and puts these knowledge into the repository; Repository stores many general principles that guide a part of the implementation action, due to environment provides all \\nkinds of information for learning system, the quality of \\ninformation impacts directly on learning realization whether \\neasy or disorderly. \\nRepository is the second factor that impacts the design of \\nlearning system. The expression of knowledge is varied, such as, eigenvector, logic statements of the first order, production rules, semantic networks and frameworks and so on, these fashions of expression each has its strong point. \\nTake into account four aspects when to choose: strong in \\nexpression, easy to infer, easy to modify repository, the knowledge is easy to expand. The implementation is the process that uses the knowledge of repository to complete a certain task, and to feed back the information which obtained in the progress of completing the task to the learning, and to guide further study. \\nFigure 1. Basic model of machine learning \\n978-1-4244-4994-1/09/$25.00 ©2009 IEEE', metadata={'source': 'C:\\\\Users\\\\ELAFACRB1\\\\Codice\\\\GitHub\\\\utils-ml\\\\large language models\\\\python\\\\langchain\\\\documents\\\\papers\\\\A brief review of machine learning and its application.pdf', 'page': 0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected EmbeddingFunction.__call__ to have the following signature: odict_keys(['self', 'input']), got odict_keys(['self', 'args', 'kwargs'])\nPlease see https://docs.trychroma.com/embeddings for details of the EmbeddingFunction interface.\nPlease note the recent change to the EmbeddingFunction interface: https://docs.trychroma.com/migration#migration-to-0416---november-7-2023 \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fullDocRetriever \u001b[38;5;241m=\u001b[39m \u001b[43mfull_doc_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcollection\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m fullDocRetriever\u001b[38;5;241m.\u001b[39madd_documents(docs, ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m, in \u001b[0;36mfull_doc_retriever\u001b[1;34m(collection)\u001b[0m\n\u001b[0;32m      4\u001b[0m child_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# The vectorstore to use to index the child chunks\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedder\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#OpenAIEmbeddings()\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# The storage layer for the parent documents\u001b[39;00m\n\u001b[0;32m     14\u001b[0m store \u001b[38;5;241m=\u001b[39m InMemoryStore()\n",
      "File \u001b[1;32mc:\\Users\\ELAFACRB1\\venvs\\langchain\\Lib\\site-packages\\langchain\\vectorstores\\chroma.py:125\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[1;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persist_directory \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    121\u001b[0m         _client_settings\u001b[38;5;241m.\u001b[39mpersist_directory \u001b[38;5;129;01mor\u001b[39;00m persist_directory\n\u001b[0;32m    122\u001b[0m     )\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;241m=\u001b[39m embedding_function\n\u001b[1;32m--> 125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embedding_function\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverride_relevance_score_fn \u001b[38;5;241m=\u001b[39m relevance_score_fn\n",
      "File \u001b[1;32mc:\\Users\\ELAFACRB1\\venvs\\langchain\\Lib\\site-packages\\chromadb\\api\\client.py:237\u001b[0m, in \u001b[0;36mClient.get_or_create_collection\u001b[1;34m(self, name, metadata, embedding_function, data_loader)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_or_create_collection\u001b[39m(\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    235\u001b[0m     data_loader: Optional[DataLoader[Loadable]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[1;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_server\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ELAFACRB1\\venvs\\langchain\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ELAFACRB1\\venvs\\langchain\\Lib\\site-packages\\chromadb\\api\\segment.py:216\u001b[0m, in \u001b[0;36mSegmentAPI.get_or_create_collection\u001b[1;34m(self, name, metadata, embedding_function, data_loader, tenant, database)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;129m@trace_method\u001b[39m(\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSegmentAPI.get_or_create_collection\u001b[39m\u001b[38;5;124m\"\u001b[39m, OpenTelemetryGranularity\u001b[38;5;241m.\u001b[39mOPERATION\n\u001b[0;32m    203\u001b[0m )\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     database: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m DEFAULT_DATABASE,\n\u001b[0;32m    215\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Collection:\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    217\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[43m        \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    220\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_or_create\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ELAFACRB1\\venvs\\langchain\\Lib\\site-packages\\chromadb\\telemetry\\opentelemetry\\__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ELAFACRB1\\venvs\\langchain\\Lib\\site-packages\\chromadb\\api\\segment.py:190\u001b[0m, in \u001b[0;36mSegmentAPI.create_collection\u001b[1;34m(self, name, metadata, embedding_function, data_loader, get_or_create, tenant, database)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_product_telemetry_client\u001b[38;5;241m.\u001b[39mcapture(\n\u001b[0;32m    183\u001b[0m     ClientCreateCollectionEvent(\n\u001b[0;32m    184\u001b[0m         collection_uuid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m),\n\u001b[0;32m    185\u001b[0m         embedding_function\u001b[38;5;241m=\u001b[39membedding_function\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m    186\u001b[0m     )\n\u001b[0;32m    187\u001b[0m )\n\u001b[0;32m    188\u001b[0m add_attributes_to_current_span({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollection_uuid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m)})\n\u001b[1;32m--> 190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoll\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoll\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtenant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtenant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatabase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ELAFACRB1\\venvs\\langchain\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:87\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[1;34m(self, client, name, id, embedding_function, data_loader, tenant, database, metadata)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Check to make sure the embedding function has the right signature, as defined by the EmbeddingFunction protocol\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[43mvalidate_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_function \u001b[38;5;241m=\u001b[39m embedding_function\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_loader \u001b[38;5;241m=\u001b[39m data_loader\n",
      "File \u001b[1;32mc:\\Users\\ELAFACRB1\\venvs\\langchain\\Lib\\site-packages\\chromadb\\api\\types.py:210\u001b[0m, in \u001b[0;36mvalidate_embedding_function\u001b[1;34m(embedding_function)\u001b[0m\n\u001b[0;32m    207\u001b[0m protocol_signature \u001b[38;5;241m=\u001b[39m signature(EmbeddingFunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_signature \u001b[38;5;241m==\u001b[39m protocol_signature:\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    211\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected EmbeddingFunction.__call__ to have the following signature: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprotocol_signature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction_signature\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease see https://docs.trychroma.com/embeddings for details of the EmbeddingFunction interface.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease note the recent change to the EmbeddingFunction interface: https://docs.trychroma.com/migration#migration-to-0416---november-7-2023 \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected EmbeddingFunction.__call__ to have the following signature: odict_keys(['self', 'input']), got odict_keys(['self', 'args', 'kwargs'])\nPlease see https://docs.trychroma.com/embeddings for details of the EmbeddingFunction interface.\nPlease note the recent change to the EmbeddingFunction interface: https://docs.trychroma.com/migration#migration-to-0416---november-7-2023 \n"
     ]
    }
   ],
   "source": [
    "fullDocRetriever = full_doc_retriever('collection')\n",
    "fullDocRetriever.add_documents(docs, ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = full_doc_retriever.get_relevant_documents(\"what is langsmith\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
